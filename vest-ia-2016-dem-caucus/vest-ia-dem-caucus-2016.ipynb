{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd73deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SamSpinner/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # for plotting maps\n",
    "import maup # mggg's library for proration, see documentation here: https://github.com/mggg/maup\n",
    "import pandas as pd # standard python data library\n",
    "import geopandas as gp # the geo-version of pandas\n",
    "import numpy as np \n",
    "from statistics import mean, median\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import tabula\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 150)\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "DATA_PATH = \"raw-from-source/\"\n",
    "CRS = 3857"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c059f",
   "metadata": {},
   "source": [
    "## Summary - VEST IA Democratic Caucus Results 2016\n",
    "\n",
    "### VEST documentation:\n",
    "\n",
    "---\n",
    "Election results from IA Democratic Party: http://iowademocrats.org/final-precinct-results-for-2016-iowa-democratic-party-caucuses/ (original url)\n",
    "Precinct shapefile from IA Secretary of State: https://sos.iowa.gov/shapefiles/\n",
    "\n",
    "The Iowa Democratic Party did not report individual vote tallies for the 2016 Iowa caucuses. The caucus results are State Delegate Equivalents that represent the number of state convention delegates that the candidates received based on the caucus results. The SDE figures are multiplied by 100 following the standard practice of the Associated Press since precinct-level SDE figures are provided as very small fractions in the actual caucus reports.\n",
    "\n",
    "The precinct results do not include the state delegates awarded via satellite locations for participants with hardship exceptions or via tele-caucus for voters abroad. The satellite locations awarded 2 state delegates to Hillary Clinton and 1 state delegate to Bernie Sanders. The tele-caucus awarded 1 state delegate to Hillary Clinton and 1 state delegate to Bernie Sanders.\n",
    "\n",
    "The following precincts were merged to match the 2016 caucus results:\n",
    "\n",
    "Appanoose: Udell/Union\n",
    "Black Hawk: Cedar Falls W2P2/Cedar Falls Twp\n",
    "Des Moines: Burlington 1/Tama, Burlington 8/Concordia\n",
    "Fremont: Hamburg/Washington, Farragut/Shenandoah1\n",
    "Polk: Grimes 2/Urbandale 12\n",
    "\n",
    "C16PREDCLI - Hillary Clinton \\\n",
    "C16PREDSAN - Bernie Sanders \\\n",
    "C16PREDOMA - Martin O'Malley \\\n",
    "C16PREDUNC - Uncommitted\n",
    "\n",
    "\n",
    "### VEST data:\n",
    "\n",
    "---\n",
    "\n",
    "**ia_2016_demcaucus.shp** \n",
    "\n",
    "Found on the standard [VEST page](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NH5S2I).\n",
    "\n",
    "\n",
    "### Election data:\n",
    "\n",
    "----\n",
    "**caucusresults020116d.pdf**\n",
    "\n",
    "Election data taken from [this site](http://www.p2016.org/chrniowa/caucusresultsrxn.html) as the link provided by VEST no longer functions. \n",
    "\n",
    "The site above also describes the subsequent modifications that were made to the original caucus results, which are presented below:\n",
    "\n",
    "_Marion County, Knoxville 3 Precinct:\n",
    "Reported As: 5 county convention delegates for Clinton, 4 county convention delegates for Sanders\n",
    "Confirmed As: 4 county convention delegates for Clinton, 5 county convention delegates for Sanders\n",
    "Net Change: Sanders gains 0.13 state delegate equivalents (SDEs); Clinton loses 0.13 SDEs_\n",
    " \n",
    "_Woodbury County, 43 Oto/Oto Township Precinct:\n",
    "Reported As: 1 county convention delegate for Clinton\n",
    "Confirmed As: 1 county convention delegate for Sanders\n",
    "Net Change: Sanders gains 0.15 SDEs, Clinton loses 0.15 SDEs_\n",
    " \n",
    "_Osceola County, Ashton Precinct:\n",
    "Reported As: 3 county convention delegates for O’Malley, 4 county convention delegates for Sanders\n",
    "Confirmed As: 4 county convention delegates for O’Malley, 3 county convention delegates fro Sanders\n",
    "Net Change: O’Malley gains 0.0167 SDEs, Sanders loses 0.0167 SDEs_\n",
    " \n",
    "_Story County, Sherman Township Precinct:\n",
    "Reported As: 1 county convention delegate for Sanders\n",
    "Confirmed As: 1 county convention delegate for Clinton\n",
    "Net Change: Clinton gains 0.23 SDEs, Sanders loses 0.23 SDEs_\n",
    " \n",
    "_Poweshiek County, 1st Ward Grinnell:\n",
    "Reported As: 18 county convention delegates for Sanders, 8 county convention delegates for Clinton\n",
    "Confirmed As: 19 county convention delegates for Sanders, 7 county convention delegates for Clinton\n",
    "Net Change: Sanders gains 0.072 SDEs, Clinton loses 0.072 SDEs_\n",
    " \n",
    "_Total net Change:\n",
    "Sanders gains 0.1053 SDEs\n",
    "Clinton loses 0.122 SDEs\n",
    "O’Malley gains 0.0167 SDEs_\n",
    " \n",
    "Updated Results:\\\n",
    "Clinton: 700.47 SDEs (--0.122 SDEs) 49.84% \\ \n",
    "Sanders: 696.92 SDEs (+0.1053 SDEs) 49.59% \\\n",
    "O’Malley: 7.63 SDEs (+0.0167 SDEs) 0.54% \\\n",
    "Uncommitted: 0.46 SDEs (unchanged) 0.03%\n",
    "\n",
    "\n",
    "#### Raw Shapefile Data\n",
    "\n",
    "---- \n",
    "**Precincts041714.shp**\n",
    "\n",
    "Raw shapefile data was found by navigating to [this site](https://sos.iowa.gov/shapefiles/) and downloading the data named \"Statewide Precinct Layer\". \n",
    "\n",
    "#### Summary\n",
    "\n",
    "----\n",
    "We are able to validate that all 1680 precincts' election results and shapefile shapes match between VEST's reported data and the raw data. \n",
    "\n",
    "<font color=\"Coral\">The following VEST precinct shapefiles are composed of 2 or more raw precinct shapefiles:</font>\n",
    "\n",
    "Cedar Falls ward 2 precinct 2/CF Twp \n",
    " \n",
    "Burlington 1-T \n",
    " \n",
    "Burlington 8-C \n",
    " \n",
    "Dickinson 6/7 \n",
    " \n",
    "Farragut \n",
    " \n",
    "Grimes Precinct 2 \n",
    " \n",
    "Hamburg/Washington \n",
    " \n",
    "Union/Udell "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a60c570",
   "metadata": {},
   "source": [
    "### Part 1 - Election data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad14841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_vest_df = gp.read_file(\"raw-from-source/vest/ia_2016_demcaucus.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4569a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vest_df = master_vest_df.copy()\n",
    "vest_df.sort_values(\"DISTRICT\").head()\n",
    "vest_df[\"ID\"] = vest_df[\"COUNTY\"] + \"<->\" + vest_df[\"DISTRICT\"]\n",
    "assert(len(vest_df[\"ID\"]) == len(vest_df[\"ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d454e",
   "metadata": {},
   "source": [
    "#### Process .pdf if not already, processed, otherwise load saved version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b84cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    \"Clinton\":\"C16PREDCLI\",\t\n",
    "    \"Sanders\":\"C16PREDSAN\",\t\n",
    "    \"O'Malley\":\"C16PREDOMA\",\t\n",
    "    \"Uncommitted\":\"C16PREDUNC\"\t\n",
    "}\n",
    "if os.path.exists(\"raw-from-source/processed_election_data.csv\"):\n",
    "    master_election_df = pd.read_csv(\"raw-from-source/processed_election_data.csv\")\n",
    "else:\n",
    "    column_tables = tabula.read_pdf(file, pages=1)\n",
    "    columns = column_tables[0].columns\n",
    "    \n",
    "    tables = tabula.read_pdf(file, pages = \"all\", multiple_tables = True, pandas_options={'header': None, \"columns\":columns})\n",
    "\n",
    "    master_election_df = pd.concat(tables, axis=0)\n",
    "    master_election_df.reset_index(inplace=True)\n",
    "    master_election_df.drop(columns=[\"Unnamed: 0\"], index=[0], inplace=True)\n",
    "\n",
    "    # replace middle Fs with spaces\n",
    "    master_election_df[\"Precinct'Name\"] = master_election_df[\"Precinct'Name\"].astype('str').str.slice(start=0, stop=1) + \\\n",
    "                                            master_election_df[\"Precinct'Name\"].astype('str').str.slice(start=1).str.split(\"F\").str.join(\" \")\n",
    "\n",
    "    master_election_df[\"Candidate\"] = master_election_df[\"Candidate\"].apply(lambda name: \\\n",
    "                                        \"Clinton\" if \"Clinton\" in name else name)\n",
    "\n",
    "    # create unique ID for merging with VEST\n",
    "    master_election_df[\"ID\"] = master_election_df[\"County'Name\"] + \"<->\" + master_election_df[\"Precinct'Name\"]\n",
    "\n",
    "\n",
    "    # nans are appearing after here for some reason\n",
    "    master_election_df = pd.pivot_table(master_election_df, index=\"ID\", columns=\"Candidate\", \n",
    "                           values=\"Candidate'State'Delegate'Equivalents\", aggfunc=\"first\")\n",
    "\n",
    "    # get ready for merge with VEST\n",
    "    master_election_df.rename(columns=rename, inplace=True)\n",
    "    master_election_df.reset_index(inplace=True)\n",
    "\n",
    "    master_election_df.to_csv(\"raw-from-source/processed_election_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31258485",
   "metadata": {},
   "source": [
    "#### Alright so there is a bug occuring, the columns of the dataframe are being \"renamed\" when a duplicate value occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ceff0b",
   "metadata": {},
   "source": [
    "#### Per VEST documentation, multiply SDE by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad902b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>C16PREDCLI</th>\n",
       "      <th>C16PREDSAN</th>\n",
       "      <th>C16PREDOMA</th>\n",
       "      <th>C16PREDUNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adair&lt;-&gt;1NW</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adair&lt;-&gt;2NE</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adair&lt;-&gt;3SW</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adair&lt;-&gt;4SE</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adair&lt;-&gt;5G</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  C16PREDCLI  C16PREDSAN  C16PREDOMA  C16PREDUNC\n",
       "0  Adair<->1NW        0.24        0.30         0.0         0.0\n",
       "1  Adair<->2NE        0.36        0.30         0.0         0.0\n",
       "2  Adair<->3SW        0.30        0.24         0.0         0.0\n",
       "3  Adair<->4SE        0.42        0.18         0.0         0.0\n",
       "4  Adair<->5G         0.36        0.30         0.0         0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "races = [\"C16PREDCLI\", \"C16PREDSAN\", \"C16PREDOMA\", \"C16PREDUNC\"]\n",
    "election_df = master_election_df.copy()\n",
    "election_df = election_df[[\"ID\"] + races]\n",
    "display(election_df.head())\n",
    "\n",
    "for v in rename.values():\n",
    "    election_df[v] = np.round(election_df[v].astype('float').to_numpy() * 100, 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa0a182",
   "metadata": {},
   "source": [
    "#### Create county column to match VEST, we are going to need to validate on a county-by-county basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51a4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Caucus Expansion Results'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "election_df[\"County\"] = election_df[\"ID\"].str.split('<->').str[0].replace(r\"\\BF\\B\", \" \", regex=True)\n",
    "election_df[\"County\"] = election_df[\"County\"].apply(lambda c: \"Obrien\" if c == \"O'Brien\" else c)\n",
    "\n",
    "print(set(election_df[\"County\"].to_list()).difference(vest_df[\"COUNTY\"].to_list()))\n",
    "print(set(vest_df[\"COUNTY\"].to_list()).difference(election_df[\"County\"].to_list()))\n",
    "\n",
    "# we may need to look at the caucus expansion results later, but for now we will get rid of them:\n",
    "election_df = election_df[election_df[\"County\"] != 'Caucus Expansion Results'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795a0207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a523a82c2ec4452a82f748e7ac212ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kossuth\n",
      "--------------------\n",
      "Some errors in sorting, no further output means we sorted it out:\n",
      "\n",
      "\n",
      "Warren\n",
      "--------------------\n",
      "Some errors in sorting, no further output means we sorted it out:\n",
      "\n",
      "\n",
      "Jasper\n",
      "--------------------\n",
      "Some errors in sorting, no further output means we sorted it out:\n",
      "\n",
      "\n",
      "Delaware\n",
      "--------------------\n",
      "Some errors in sorting, no further output means we sorted it out:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vest_ids = []\n",
    "raw_idxs = []\n",
    "\n",
    "for county in tqdm(vest_df[\"COUNTY\"].unique()):\n",
    "\n",
    "    v = vest_df[vest_df[\"COUNTY\"] == county].copy()\n",
    "    e = election_df[election_df[\"County\"] == county].copy()\n",
    "    \n",
    "    v.reset_index(inplace=True)\n",
    "    e.reset_index(inplace=True)\n",
    "    \n",
    "    v[\"SORT\"] = v[races[0]].astype('str') + \" \" + v[races[1]].astype('str') + \" \" + str(v[races].sum(axis=1)) + \" \"  + v[\"ID\"]\n",
    "    e[\"SORT\"] = e[races[0]].astype('str') + \" \" + e[races[1]].astype('str') + \" \" + str(e[races].sum(axis=1)) + \" \"  + e[\"ID\"]\n",
    "    \n",
    "    v = v.sort_values(by=\"SORT\")\n",
    "    e = e.sort_values(by=\"SORT\")\n",
    "     \n",
    "    assert(len(v) == len(e))\n",
    "    \n",
    "    v_votes = v[races].to_numpy()\n",
    "    e_votes = e[races].to_numpy()\n",
    "    \n",
    "    if np.array_equal(v_votes, e_votes):\n",
    "        vest_ids.extend(v[\"ID\"].to_list())\n",
    "        raw_idxs.extend(e[\"ID\"].to_list())\n",
    "        continue\n",
    "        \n",
    "    wrong_idxs_v = []\n",
    "    wrong_idxs_e = []\n",
    "        \n",
    "    print(county)\n",
    "    print('-' * 20)\n",
    "    print(\"Some errors in sorting, no further output means we sorted it out:\\n\")\n",
    "    \n",
    "    for idx in range(len(v)):\n",
    "        if np.array_equal(v_votes[idx], e_votes[idx]):\n",
    "            vest_ids.append(v[\"ID\"].iloc[idx])\n",
    "            raw_idxs.append(e[\"ID\"].iloc[idx])\n",
    "        \n",
    "        else:\n",
    "            wrong_idxs_v.append(idx)\n",
    "            wrong_idxs_e.append(idx)\n",
    "            \n",
    "    used_e = set()\n",
    "            \n",
    "    for v_idx in wrong_idxs_v:\n",
    "        for e_idx in wrong_idxs_e:\n",
    "            if e_idx in used_e:\n",
    "                continue\n",
    "                \n",
    "            if np.array_equal(v_votes[v_idx], e_votes[e_idx]):\n",
    "                vest_ids.append(v[\"ID\"].iloc[v_idx])\n",
    "                raw_idxs.append(e[\"ID\"].iloc[e_idx])\n",
    "                used_e.add(e_idx)\n",
    "                continue\n",
    "                \n",
    "    if len(used_e) != len(wrong_idxs_e):\n",
    "        print(\"Something has still gone awry :(\")\n",
    "            \n",
    "#     print(np.array_equal(v_votes, e_votes))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a93ce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1681\n",
      "1681\n"
     ]
    }
   ],
   "source": [
    "print(len(vest_ids))\n",
    "print(len(raw_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97051b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "raw2vest = {raw : vest for raw, vest in zip(raw_idxs, vest_ids)}\n",
    "election_df[\"ORIG_ID\"] = election_df[\"ID\"].to_numpy()\n",
    "election_df[\"ID\"] = election_df[\"ID\"].apply(lambda name: raw2vest[name] if name in raw2vest else name)\n",
    "\n",
    "in_e = election_df[~election_df[\"ID\"].isin(vest_df[\"ID\"])]\n",
    "in_v = vest_df[~vest_df[\"ID\"].isin(election_df[\"ID\"])]\n",
    "\n",
    "print(len(in_e))\n",
    "print(len(in_v))\n",
    "\n",
    "election_df[\"ORIG_PRC\"] = election_df[\"ORIG_ID\"].str.split('<->').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf6df9",
   "metadata": {},
   "source": [
    "#### Merge raw election results to VEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a21dcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1681, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recreated_df = vest_df.merge(election_df, on=\"ID\", how=\"outer\")\n",
    "recreated_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3b1fe",
   "metadata": {},
   "source": [
    "### Part 2 - Shapfile data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79986be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_shape_df = gp.read_file(\"raw-from-source/raw_shapes/Precincts041714.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "459af32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_df = master_shape_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b2bc490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1681 VEST precincts.\n",
      "There are 1689 raw shape precincts.\n",
      "There are 1681 raw election precincts.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(vest_df['geometry'].dropna())} VEST precincts.\")\n",
    "print(f\"There are {len(shape_df['geometry'].dropna())} raw shape precincts.\")\n",
    "print(f\"There are {len(election_df)} raw election precincts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8badfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa52b7bbfba4d369d221b010b6eb62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geoms = []\n",
    "vest_ids = []\n",
    "geom_names = []\n",
    "\n",
    "shape_df.crs = CRS\n",
    "recreated_df.crs = CRS\n",
    "\n",
    "idx2area = defaultdict(list)\n",
    "vestidx2rawidx = defaultdict(list)\n",
    "\n",
    "for raw_idx, geom in enumerate(tqdm(shape_df[\"geometry\"])):\n",
    "    vest_matches = recreated_df[recreated_df[\"geometry\"].geom_almost_equals(geom)].copy()\n",
    "    geoms.append(geom)\n",
    "    geom_names.append(shape_df[\"NAME\"].iloc[raw_idx])\n",
    "    # we got a perfect match\n",
    "    if len(vest_matches) == 1:\n",
    "        vest_ids.append(vest_matches.index[0])\n",
    "        continue\n",
    "        \n",
    "    # no perfect match, let's scan the surrounding area\n",
    "    vest_matches = recreated_df[recreated_df[\"geometry\"].intersects(geom)].copy()\n",
    "    orig_idxs = vest_matches.index\n",
    "    \n",
    "    vest_matches.reset_index(inplace=True)\n",
    "    \n",
    "    shared = vest_matches.intersection(geom).area.to_numpy() / vest_matches.area.to_numpy()\n",
    "    \n",
    "    # choose the precinct that overlapped the most with the raw shapefile\n",
    "    correct_idx = orig_idxs[np.argmax(shared)]\n",
    "    \n",
    "    idx2area[correct_idx].append(np.amax(shared))\n",
    "    vestidx2rawidx[correct_idx].append(raw_idx)\n",
    "    \n",
    "    \n",
    "    vest_ids.append(correct_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3c2017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9866114952284425, 0.0042830702041175015, 0.009105434567440122] Sum: 1.0000000000000002\n",
      "[0.9999501246485349, 4.987535146822659e-05] Sum: 1.000000000000003\n",
      "[0.5050685673789276, 0.49493143262107264] Sum: 1.0000000000000002\n",
      "[0.04023852473346539, 0.9597614752665348] Sum: 1.0000000000000002\n",
      "[0.8942092763768601, 0.10579072362313927] Sum: 0.9999999999999993\n",
      "[0.870689512083456, 0.12931048791654223] Sum: 0.9999999999999982\n",
      "[0.8638398261704965, 0.13616017382950432] Sum: 1.0000000000000009\n"
     ]
    }
   ],
   "source": [
    "doubled_idxs = {key : val for key, val in idx2area.items() if len(val) > 1}\n",
    "for idx, lst in doubled_idxs.items():\n",
    "    print(lst, \"Sum:\", sum([float(l) for l in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e50666",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_join = gp.GeoDataFrame(data={\"index\" : vest_ids, \"NAMES\" : geom_names}, geometry=geoms)\n",
    "to_join.sort_values(by=\"index\", inplace=True)\n",
    "to_join = to_join.dissolve(\"index\", aggfunc=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0717879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recreated_df[\"geometry_y\"] = to_join[\"geometry\"]\n",
    "recreated_df[\"RAW_GEOM_NAMES\"] = to_join[\"NAMES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd9b9b",
   "metadata": {},
   "source": [
    "### Part 3: Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8ad3a",
   "metadata": {},
   "source": [
    "#### Check Vote Totals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6823232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all vote totals correct?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validater_row_vect(df, name_column, column_list, verbose=False):\n",
    "    matching_rows = 0\n",
    "    different_rows = 0\n",
    "    \n",
    "    county_join_cols = (df[name_column]).to_numpy()\n",
    "    \n",
    "    # it's because before, we were checking that a row was entirely consistent\n",
    "    # here, we are double checking a lot\n",
    "    # so, let's just keep one track of the rows that are messed up\n",
    "    \n",
    "    wrong_idxs = np.zeros(len(df))\n",
    "    for i in column_list:\n",
    "        left_data = df[i + \"_x\"].to_numpy()\n",
    "        right_data = df[i + \"_y\"].to_numpy()\n",
    "        \n",
    "        local_idxs = np.where(left_data != right_data)\n",
    "        wrong_idxs[local_idxs] = 1\n",
    "        #print(\"Wrong idxs\", wrong_idxs)\n",
    "        \n",
    "    # we are close, we get the same result, but are double adding lots of rows\n",
    "    different_rows += np.sum(wrong_idxs)\n",
    "    matching_rows += len(df) - different_rows\n",
    "    \n",
    "    diff_list = county_join_cols[np.where(wrong_idxs == 1)]\n",
    "    diff_counties = list(set([county[:2] for county in diff_list]))\n",
    "    \n",
    "    if int(different_rows) != 0 or verbose:\n",
    "        print(\"There are \", len(df.index),\" total rows\")\n",
    "        print(f\"{int(different_rows)} of these rows have election result differences\")\n",
    "        print(f\"{int(matching_rows)} of these rows are the same\")\n",
    "        print(diff_list)\n",
    "        print(\"\")\n",
    "        \n",
    "    return (int(different_rows) == 0, diff_list)\n",
    "\n",
    "print(\"Are all vote totals correct?\")\n",
    "validater_row_vect(recreated_df, \"ID\", races)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e516b78",
   "metadata": {},
   "source": [
    "#### Check shapefile geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea92261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1681 precincts.\n",
      "1645 of those precincts' shapefiles match exactly.\n",
      "\n",
      "Of the remaining 36 precincts:\n",
      "36 precincts contain a difference of less than 0.1 km^2.\n",
      "\n",
      "The shapefiles and election results match exactly between the raw files and VEST.\n"
     ]
    }
   ],
   "source": [
    "vest_shapes = gp.GeoSeries(recreated_df[\"geometry\"])\n",
    "raw_shapes = gp.GeoSeries(recreated_df[\"geometry_y\"])\n",
    "\n",
    "vest_shapes.crs = CRS\n",
    "raw_shapes.crs = CRS\n",
    "\n",
    "print(f\"There are {len(election_df)} precincts.\")\n",
    "\n",
    "same_shapes = vest_shapes[vest_shapes.geom_almost_equals(raw_shapes, decimal=0)]\n",
    "\n",
    "print(f\"{len(same_shapes)} of those precincts' shapefiles match exactly.\\n\")\n",
    "\n",
    "different_vest = vest_shapes[~vest_shapes.geom_almost_equals(raw_shapes, decimal=0)]\n",
    "different_raw = raw_shapes[~raw_shapes.geom_almost_equals(vest_shapes, decimal=0)]\n",
    "\n",
    "different_vest_area = different_vest.area.to_numpy() \n",
    "different_raw_area = different_raw.area.to_numpy()\n",
    "\n",
    "area_diff = np.abs(different_vest_area - different_raw_area)\n",
    "\n",
    "print(f\"Of the remaining {len(area_diff)} precincts:\")\n",
    "print(f\"{len(area_diff[area_diff < .1])} precincts contain a difference of less than 0.1 km^2.\")\n",
    "\n",
    "\n",
    "print(\"\\nThe shapefiles and election results match exactly between the raw files and VEST.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c412fd0",
   "metadata": {},
   "source": [
    "#### Dataframe containing the precinct names that were assigned to one another from the VEST, raw election, and raw shapefile data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28bbb88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ORIG_PRC</th>\n",
       "      <th>RAW_GEOM_NAMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precinct No. 08</td>\n",
       "      <td>Precinct No. 8</td>\n",
       "      <td>Dickinson 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precinct No. 09</td>\n",
       "      <td>Precinct No. 9</td>\n",
       "      <td>Dicksinon 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake-Freeman</td>\n",
       "      <td>LakeI reeman</td>\n",
       "      <td>Lake/Freeman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summit-Riverton-Sioux-Meadow</td>\n",
       "      <td>SummitIRivertonISiouxIMeadow</td>\n",
       "      <td>Summit/Riverton/Sioux/Meadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waterford-Lone Tree</td>\n",
       "      <td>WaterfordILone Tree</td>\n",
       "      <td>Waterford/Lone Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>Toledo 3</td>\n",
       "      <td>CARLTON</td>\n",
       "      <td>Tama 15 - Toledo 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>Toledo 2</td>\n",
       "      <td>HIGHLAND/INDIAN VILLAGE</td>\n",
       "      <td>Tama 14 - Toledo 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Highland/Indian Village</td>\n",
       "      <td>TOLEDO 2</td>\n",
       "      <td>Tama 8 - Highland/Indian Village/Tama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Columbia/Tama</td>\n",
       "      <td>COLUMBIA/TAMA</td>\n",
       "      <td>Tama 5 - Columbia/Tama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Indian Settlement</td>\n",
       "      <td>INDIAN SETTLEMENT</td>\n",
       "      <td>Tama 9 - Indian Settlement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1681 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              NAME                      ORIG_PRC  \\\n",
       "0                  Precinct No. 08                Precinct No. 8   \n",
       "1                  Precinct No. 09                Precinct No. 9   \n",
       "2                     Lake-Freeman                  LakeI reeman   \n",
       "3     Summit-Riverton-Sioux-Meadow  SummitIRivertonISiouxIMeadow   \n",
       "4              Waterford-Lone Tree           WaterfordILone Tree   \n",
       "...                            ...                           ...   \n",
       "1676                      Toledo 3                       CARLTON   \n",
       "1677                      Toledo 2       HIGHLAND/INDIAN VILLAGE   \n",
       "1678       Highland/Indian Village                      TOLEDO 2   \n",
       "1679                 Columbia/Tama                 COLUMBIA/TAMA   \n",
       "1680             Indian Settlement             INDIAN SETTLEMENT   \n",
       "\n",
       "                             RAW_GEOM_NAMES  \n",
       "0                               Dickinson 8  \n",
       "1                               Dicksinon 9  \n",
       "2                              Lake/Freeman  \n",
       "3              Summit/Riverton/Sioux/Meadow  \n",
       "4                       Waterford/Lone Tree  \n",
       "...                                     ...  \n",
       "1676                     Tama 15 - Toledo 3  \n",
       "1677                     Tama 14 - Toledo 2  \n",
       "1678  Tama 8 - Highland/Indian Village/Tama  \n",
       "1679                 Tama 5 - Columbia/Tama  \n",
       "1680             Tama 9 - Indian Settlement  \n",
       "\n",
       "[1681 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_comparison = recreated_df[[\"NAME\", \"ORIG_PRC\", \"RAW_GEOM_NAMES\"]]\n",
    "name_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c82c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
